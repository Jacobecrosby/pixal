# =====================================
#  ██████╗ ██╗██╗  ██╗ █████╗ ██╗     
#  ██╔══██╗██║╚██╗██╔╝██╔══██╗██║     
#  ██████╔╝██║ ╚███╔╝ ███████║██║     
#  ██╔═══╝ ██║ ██╔██╗ ██╔══██║██║     
#  ██║     ██║██╔╝ ██╗██║  ██║███████╗
#  ╚═╝     ╚═╝╚═╝  ╚═╝╚═╝  ╚═╝╚══════╝
#   PIXAL – PIXel-based Anomaly Locator
# =====================================

###
##
#
##
###
experimentName: "Test_Experiment"  # Name of the MLflow experiment to log results to. If it doesn't exist, it will be created.

########## ----> Preprocessing <---- ###########
preprocessing:
  # Thread count for CPU usage
  remove_background: 
    max_workers: 8                                  # Number of CPU threads to use for preprocessing

  # Settings for image alignment
  alignment:
    apply_alignment: False
    knn_ratio: 0.8                                 # Ratio for KNN matching. Lower for more strict matching
    number_of_points: 5                            # Number of points to match between images
    ransac_threshold: 7.0                           # RANSAC threshold for outlier removal (removes points that are too far)
    MIN_SCORE_THRESHOLD: 0.5
    MAX_MSE_THRESHOLD: 10.0
    MIN_GOOD_MATCHES: 20

  save_metrics: True                                # Save alignment metrics
  save_overlays: True                              # Save overlays of aligned images
  draw_matches: True                             # Draw matches between images and save them to disk

  # Settings for preprocessing images to .npz format for ML input
  preprocessor:
    file_name: "out.npz"
    pool_size: 2                                   # Pooling size for image pixels (e.g. 2x2 pooling) 
    # Reccommended Combinations: ["LAB_a", "LAB_b", "GradMag"] or ["LAB_a", "LAB_b", "LCh_sinH", "LCh_cosH", "GradMag", "LocalStd"] or ["ALL"]
    channels: ["LAB_a", "LAB_b"]                # Pixel data channels to save for ML input (Can be ruduced, e.g. ["R", "G", "B"]). All possible variables ["R","G","B","H","S","V","Y","Cr","Cb","LAB_L","LAB_a","LAB_b","LCh_C","LCh_sinH","LCh_cosH","r_chroma","g_chroma","Opp_O1","Opp_O2","Opp_O3","GradMag","Laplacian","LocalStd"]
    weights: [3.0,     3.0] # Weights for each channel (must be same length as channels). These weights are used for calculating the loss during training. Higher weight means more important.
    zero_pruning: True                       # Prunes zero pixels from the image. If True, only non-zero pixels are saved to the .npz file. This is useful for sparse data.
    zero_pruning_padding: 5                        # Prune pixels that are within this distance from the edge of the image. This is useful for images with a lot of padding.
    bg_threshold: 15                                 # Threshold for background removal. Pixels with a value below this threshold are considered background and removed.
  rename_images: True                              # Rename images to folder name (R0_Triplet_Data_Flex_F1_F_Pink_bg/image.png -> R0_Triplet_Data_Flex_F1_F_Pink_bg/R0_Triplet_Data_Flex_F1_F_Pink_bg.png)


########### ----> Memory Handling, Inputs and Hyperparameters<----####
model_training:
  #### ----> Memory <---- ####
  enable_memory_growth: False
  TF_GPU_ALLOCATOR: False
  mixed_precision: False

  #### ----> CPU <---- ####
  Available_CPU: 24
  CPU_MULTI_THREADING: False
  HYBRID_MODE: False  # utilize both CPU and GPU

  ########## ----> Model <---- ###########
  model_name: "testModel" 
  model_file_extension: "h5" # h5 to save weights
  seed: 101

  #### ----> Architecture <---- ####
  one_hot_encoding: False # Use one-hot encoding to train a model using all types of images. If False, a different model will be trained for each type of image. Currently underperforms separate models.
  autoencoder_architecture: [512,256,128,64] # Last index is latent layer. Gets mirrored in code
  label_latent_size: 16 # Size of the latent layer for the label. This gets added to the latent layer of the autoencoder

  ########## ----> Training <---- ##########
  use_gradient_tape: False # Gradient tape is used for full control of training cycle. Such as custom loss functions, custom optimization, etc. (reinforcement learning, adversarial learning)

  ### ----> NN Hyperparameters <---- ###
  n_epochs: 500
  batchsize: 32

  learning_rate: 1e-4
  regularization: 'l2' # 'l2' or 'l1' 
  l1_regularization: 0.0001 # Encourages zero weights. Helps feature selection. Smaller values: ex. 1e-4 Apply lighter regularization, allowing weights to grow larger without as much penalty.
  l2_regularization: 1.0e-05 # Discourages zero weights. General stability. Smaller values: ex. 1e-4 Apply lighter regularization, allowing weights to grow larger without as much penalty.
  loss_function: "huber" # "mse", 'mae', masked_mse, Huber, charbonnier
  huber_delta: 0.25 # Delta value for Huber loss function
  masked_loss: True # Masked loss ignores zero pixels in the loss calculation. This is useful for sparse data.
  metric_accuracy: "SparseCategoricalAccuracy" #CategoricalAccuracy <--- May need this when implementing image sets
  output_activation: "sigmoid" # sigmoid, softmax, tanh, relu, linear

  ### ----> STOP LOSS <---- ###
  patience: 30
  min_delta: 0.001

#
##
###
####
##### ----> PLOTTING <----#####

plotting:
  plot_loss: True
  plot_accuracy: True
  plot_confusion_matrix: False
  plot_roc_recall_curve: True
  plot_anomaly_heatmap: True
  plot_abs_loss_per_pixel: True
  plot_mse_per_pixel: True
  plot_pixel_predictions: True
  plot_distributions: True

  use_log_loss: False  # Use log loss for plotting
  loss_cut: 0.1  # Cut off for loss plotting