# =====================================
#  ██████╗ ██╗██╗  ██╗ █████╗ ██╗     
#  ██╔══██╗██║╚██╗██╔╝██╔══██╗██║     
#  ██████╔╝██║ ╚███╔╝ ███████║██║     
#  ██╔═══╝ ██║ ██╔██╗ ██╔══██║██║     
#  ██║     ██║██╔╝ ██╗██║  ██║███████╗
#  ╚═╝     ╚═╝╚═╝  ╚═╝╚═╝  ╚═╝╚══════╝
#   PIXAL – PIXel-based Anomaly Locator
# =====================================

###
##
#
##
###
########## ----> Preprocessing <---- ###########
# Thread count for CPU usage
remove_background: 
  max_workers: 8                                  # Number of CPU threads to use for preprocessing

# Settings for image alignment
alignment:
  knn_ratio: 0.55                                 # Ratio for KNN matching
  number_of_points: 10                            # Number of points to match between images
  ransac_threshold: 7.0                           # RANSAC threshold for outlier removal (removes points that are too far)

save_metrics: True                                # Save alignment metrics

# Settings for preprocessing images to .npz format for ML input
preprocessor:
  pool_size: 4                                   # Pooling size for image pixels (e.g. 2x2 pooling) 
  channels: ["H","S","V"]                        # Pixel data channels to save for ML input (Can be ruduced, e.g. ["R", "G", "B"]) ["R", "G", "B","H","S","V"]


########### ----> Memory Handling, Inputs and Hyperparameters<----####

#### ----> Memory <---- ####
enable_memory_growth: False
TF_GPU_ALLOCATOR: False
mixed_precision: False

#### ----> CPU <---- ####
Available_CPU: 24
CPU_MULTI_THREADING: False
HYBRID_MODE: False  # utilize both CPU and GPU

########## ----> Model <---- ###########
model_name: "testModel" 
seed: 101

#### ----> Architecture <---- ####

autoencoder_architecture: [800,400,200,100,50] # Last index is latent layer. Gets mirrored in code
label_latent_size: 50 # Size of the latent layer for the label. This gets added to the latent layer of the autoencoder

########## ----> Training <---- ##########
use_gradient_tape: False # Gradient tape is used for full control of training cycle. Such as custom loss functions, custom optimization, etc. (reinforcement learning, adversarial learning)

### ----> NN Hyperparameters <---- ###
n_epochs: 500
batchsize: 8

learning_rate: 1e-5
l2_regularization: 0.01 #smaller values: ex. 1e-4 Apply lighter regularization, allowing weights to grow larger without as much penalty.
loss_function: "mse"
metric_accuracy: "SparseCategoricalAccuracy" #CategoricalAccuracy <--- May need this when implementing image sets

### ----> STOP LOSS <---- ###
patience: 30
min_delta: 3

#
##
###
####
##### ----> PLOTTING <----#####

scatter_comparison: ['forward', 'data'] #,'backward']  # this plots backward passing, forward passing, and data on same plot. Remove any if once cares to do so

plot_modulus: 10  # makes number of plots w.r.t. modulus of latent size

guassian_fig_size: 10  # x and y bounds of gaussian figure

## Used for testing ideal z-space (gaussian distribution), with fake signal (no idea if anomalies would be found here)
use_test_gaussian: True
inject_signal: False


